{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dffc1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c91eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.mae import MaskedAutoencoderViT\n",
    "from src.utils.misc import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9b3c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai import data\n",
    "from monai import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864833d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_seed(seed):\n",
    "    random_seed = seed\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3513a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b980713",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = [128, 128, 128]\n",
    "\n",
    "trans = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(\n",
    "            keys=[\"image\", \"label\"], \n",
    "            image_only=False,\n",
    "            allow_missing_keys=True,\n",
    "        ),\n",
    "        transforms.EnsureChannelFirstd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            allow_missing_keys=True,\n",
    "        ),\n",
    "        transforms.Orientationd(\n",
    "            keys=[\"image\",\"label\"], \n",
    "            axcodes=\"RAS\",\n",
    "            allow_missing_keys=True,\n",
    "        ),\n",
    "        transforms.Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "            allow_missing_keys=True,\n",
    "        ),\n",
    "        transforms.ScaleIntensityRanged(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            a_min=40-150,\n",
    "            a_max=40+150,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "            allow_missing_keys=True,\n",
    "        ),\n",
    "        transforms.CropForegroundd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            source_key=\"image\",\n",
    "            allow_smaller=False,\n",
    "            allow_missing_keys=True,\n",
    "        ),\n",
    "        transforms.RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            roi_size=(roi[0], roi[1], roi[2]),\n",
    "            random_center=True,\n",
    "            random_size=False,\n",
    "            allow_missing_keys=True,\n",
    "        ),\n",
    "        transforms.ResizeWithPadOrCropd(\n",
    "            keys=[\"image\",\"label\"],\n",
    "            spatial_size=(roi[0], roi[1], roi[2]),\n",
    "            method='symmetric',\n",
    "            mode='constant',\n",
    "            value=0,\n",
    "            allow_missing_keys=True,\n",
    "        ),\n",
    "        transforms.ToTensord(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            allow_missing_keys=True,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32427fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "test_csv_path = '/gpfs/data/denizlab/Users/hh2740/git_backups/MedSSL-3D/datasets/debug.csv'\n",
    "\n",
    "# Load Data\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "img_test = list(df_test['img_path'])\n",
    "\n",
    "test_files = create_dataset(img_test, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d70089a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = data.Dataset(\n",
    "    data=test_files, \n",
    "    transform=trans,\n",
    ")\n",
    "\n",
    "test_loader = data.DataLoader(\n",
    "    dataset=test_ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed2c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.pos_embed import interpolate_pos_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6db04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16a094ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskedAutoencoderViT(\n",
    "    input_size=128,\n",
    "    patch_size=16,\n",
    "    mask_ratio=0.50,\n",
    "    in_chans=1,\n",
    "    dropout_rate=0.,\n",
    "    spatial_dims=3,\n",
    "    patch_embed='conv',\n",
    "    pos_embed='sincos',\n",
    "    encoder_depth=12,\n",
    "    encoder_embed_dim=768,\n",
    "    encoder_mlp_dim=3072,\n",
    "    encoder_num_heads=12,\n",
    "    decoder_depth=8,\n",
    "    decoder_embed_dim=768,\n",
    "    decoder_mlp_dim=3072,\n",
    "    decoder_num_heads=16,\n",
    "    norm_pix_loss=False,\n",
    "    use_bias=True,\n",
    "    use_flash_attn=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "270abae4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Pretrained Model: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "model_path = '/gpfs/data/denizlab/Users/hh2740/git_backups/MedSSL-3D/model_saved/mae_full_lr1.6e-3_mask0.75_sincos_pflash_ep1600_v2_gpu4_s42.pt'\n",
    "\n",
    "# Load model with wrong size weights unloaded\n",
    "if model_path != None:\n",
    "    loaded_state_dict = torch.load(model_path, map_location=torch.device('cpu'))['state_dict']\n",
    "    current_model_dict = model.state_dict()\n",
    "    new_state_dict = {k:v if v.size()==current_model_dict[k].size() else current_model_dict[k] \\\n",
    "                    for k,v in zip(current_model_dict.keys(), loaded_state_dict.values())}\n",
    "    msg = model.load_state_dict(new_state_dict, strict=False)\n",
    "    print(f\"Load Pretrained Model: {msg}\")\n",
    "    # interpolate position embedding\n",
    "    interpolate_pos_embed(model, new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16574576",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b515060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16):\n",
    "        x = batch_data['image'].to(device)\n",
    "        loss, y, mask = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b1564a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512, 4096]), torch.Size([1, 512]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91b48d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unpatch = model.unpatchify(y, x)\n",
    "y_unpatch = torch.einsum('nchwd->nhwdc', y_unpatch).detach().cpu()\n",
    "\n",
    "mask = mask.detach()\n",
    "mask = mask.unsqueeze(-1).repeat(1, 1, model.out_chans)\n",
    "\n",
    "mask_unpatch = model.unpatchify(mask, x)  # 1 is removing, 0 is keeping\n",
    "mask_unpatch = torch.einsum('nchwd->nhwdc', mask_unpatch).detach().cpu()\n",
    "\n",
    "x_ori = torch.einsum('nchwd->nhwdc', x).detach().cpu()\n",
    "\n",
    "# masked image\n",
    "im_masked = x_ori * (1 - mask_unpatch)\n",
    "\n",
    "# MAE reconstruction pasted with visible patches\n",
    "im_paste = x_ori * (1 - mask_unpatch) + y_unpatch * mask_unpatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ae94630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128, 128, 128, 1]),\n",
       " torch.Size([1, 128, 128, 128, 1]),\n",
       " torch.Size([1, 128, 128, 128, 1]),\n",
       " torch.Size([1, 128, 128, 128, 1]),\n",
       " torch.Size([1, 128, 128, 128, 1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ori.shape, y_unpatch.shape, mask_unpatch.shape, im_masked.shape, im_paste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38cc932d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ori = np.array(x_ori[0].squeeze())\n",
    "masked = np.array(im_masked[0].squeeze())\n",
    "recon = np.array(y_unpatch[0].squeeze())\n",
    "recon_vis = np.array(im_paste[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01520374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "def visualize_mae(ori, masked, recon, recon_vis, max_slices=64):\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(16, 8))\n",
    "\n",
    "    # Set titles for each axis (subplot)\n",
    "    ax1.set_title(\"original\")\n",
    "    ax2.set_title(\"masked\")\n",
    "    ax3.set_title(\"reconstruction\")\n",
    "    ax4.set_title(\"reconstruction + visible\")\n",
    "\n",
    "    ax1.axis('off')\n",
    "    ax2.axis('off')\n",
    "    ax3.axis('off')\n",
    "    ax4.axis('off')\n",
    "\n",
    "    im1 = ax1.imshow(ori[:, :, 0], animated=True, cmap=\"gray\")\n",
    "    im2 = ax2.imshow(masked[:, :, 0], animated=True, cmap=\"gray\")\n",
    "    im3 = ax3.imshow(recon[:, :, 0], animated=True, cmap=\"gray\")\n",
    "    im4 = ax4.imshow(recon_vis[:, :, 0], animated=True, cmap=\"gray\")\n",
    "\n",
    "    # Slider setup\n",
    "    max_slices = 64\n",
    "    depth = ori.shape[2]\n",
    "    step = 1 if max_slices is None else max(1, depth // max_slices)\n",
    "    # Initialize the text label and store its reference\n",
    "    slice_label1 = ax1.text(ori.shape[2]-10, ori.shape[1]-10, f\"0/{depth}\", \n",
    "                           ha=\"right\", va=\"bottom\", color=\"white\", fontsize=8, weight=\"bold\")\n",
    "    slice_label2 = ax2.text(masked.shape[2]-10, masked.shape[1]-10, f\"0/{depth}\", \n",
    "                           ha=\"right\", va=\"bottom\", color=\"white\", fontsize=8, weight=\"bold\")\n",
    "    slice_label3 = ax3.text(recon.shape[2]-10, recon.shape[1]-10, f\"0/{depth}\", \n",
    "                           ha=\"right\", va=\"bottom\", color=\"white\", fontsize=8, weight=\"bold\")\n",
    "    slice_label4 = ax4.text(recon_vis.shape[2]-10, recon_vis.shape[1]-10, f\"0/{depth}\", \n",
    "                           ha=\"right\", va=\"bottom\", color=\"white\", fontsize=8, weight=\"bold\")\n",
    "\n",
    "    def update(frame):\n",
    "        im1.set_array(ori[:, :, frame])\n",
    "        im2.set_array(masked[:, :, frame])\n",
    "        im3.set_array(recon[:, :, frame])\n",
    "        im4.set_array(recon_vis[:, :, frame])\n",
    "\n",
    "        slice_label1.set_text(f\"{frame}/{depth}\")\n",
    "        slice_label2.set_text(f\"{frame}/{depth}\")\n",
    "        slice_label3.set_text(f\"{frame}/{depth}\")\n",
    "        slice_label4.set_text(f\"{frame}/{depth}\")\n",
    "\n",
    "        return [im1, im2, im3, im4]\n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=range(0, depth, step), interval=200, blit=True)\n",
    "    \n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e568f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_slices = 64\n",
    "anim = visualize_mae(ori, masked, recon, recon_vis, max_slices=max_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346abc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2214b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the animation\n",
    "anim.save('./animation/sample_mask0.75_pflash.mp4', writer='ffmpeg', fps=15, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c41278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
